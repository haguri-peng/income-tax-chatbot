import streamlit as st

from dotenv import load_dotenv
from llm import get_ai_response, get_rag_chain

load_dotenv()

st.set_page_config(page_title="ì†Œë“ì„¸ ì±—ë´‡", page_icon="ğŸ¤–")

# ì•± ìµœì´ˆ ì‹¤í–‰ ì‹œ RAG ì²´ì¸ ë¯¸ë¦¬ ì´ˆê¸°í™” (ìºì‹± íŠ¸ë¦¬ê±°)
with st.spinner("ì†Œë“ì„¸ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒë§Œ ê±¸ë ¤ìš” ğŸ¤–)"):
    get_rag_chain()  # ë¯¸ë¦¬ í˜¸ì¶œí•´ì„œ ìºì‹± íŠ¸ë¦¬ê±°

st.title("ğŸ¤– ì†Œë“ì„¸ ì±—ë´‡")
st.caption("ì†Œë“ì„¸ì— ê´€ë ¨ëœ ëª¨ë“ ê²ƒì„ ë‹µí•´ë“œë¦½ë‹ˆë‹¤!")

# ========== ëŒ€í™” ==========
# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ìœ ì§€
if 'message_list' not in st.session_state:
    st.session_state.message_list = []

# ì´ì „ ë©”ì‹œì§€ë“¤ ë Œë”ë§
for message in st.session_state.message_list:
    with st.chat_message(message["role"]):  # "user" or "ai"
        st.markdown(message["content"], unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥
if user_question := st.chat_input(placeholder="ì†Œë“ì„¸ì— ê´€ë ¨ëœ ê¶ê¸ˆí•œ ë‚´ìš©ë“¤ì„ ë§ì”€í•´ì£¼ì„¸ìš”!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ ì¶”ê°€ ë° í‘œì‹œ
    st.session_state.message_list.append({"role": "user", "content": user_question})
    with st.chat_message("user"):
        st.markdown(user_question)

    # AI ì‘ë‹µ ë²„ë¸” ìƒì„±
    with st.chat_message("ai"):
        message_placeholder = st.empty()  # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ìš© placeholder
        full_response = ""

        # ìŠ¤í”¼ë„ˆì™€ í•¨ê»˜ ìŠ¤íŠ¸ë¦¬ë°
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            for chunk in get_ai_response(user_question):
                full_response += chunk
                message_placeholder.markdown(full_response + "â–Œ")  # ì»¤ì„œ íš¨ê³¼

        # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… í…ìŠ¤íŠ¸ í‘œì‹œ
        message_placeholder.markdown(full_response)

    # ìŠ¤íŠ¸ë¦¬ë°ì´ ì™„ì „íˆ ëë‚œ í›„ì—ë§Œ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ â†’ rerun 1íšŒë§Œ ë°œìƒ
    st.session_state.message_list.append({"role": "ai", "content": full_response})
